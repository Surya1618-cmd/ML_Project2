import os
import sys
from dataclasses import dataclass
import pandas as pd
import numpy as np
import dill # Added for saving/loading objects

from sklearn.ensemble import (
    AdaBoostClassifier,
    GradientBoostingClassifier,
    RandomForestClassifier,
    HistGradientBoostingClassifier,
)
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score
from sklearn.model_selection import GridSearchCV
from sklearn.multioutput import MultiOutputClassifier
from sklearn.tree import DecisionTreeClassifier
# Removed all preprocessing imports as data_transform.py handles it

from src.exception import CustomException
from src.logger import get_logger
from src.utils import save_object, load_object, evaluate_models # Added load_object

logging = get_logger(__name__)

@dataclass
class ModelTrainerConfig:
    trained_model_file_path: str = os.path.join("artifacts", "model.pkl")
    # No longer saves preprocessor or feature_columns here, just loads their paths
    preprocessor_file_path: str = os.path.join("artifacts", "preprocessor.pkl") 
    feature_columns_file_path: str = os.path.join("artifacts", "feature_columns.pkl")
    
    # Paths for processed data from data_transform.py
    train_processed_path: str = os.path.join("artifacts", "train_processed.csv")
    test_processed_path: str = os.path.join("artifacts", "test_processed.csv")


class ModelTrainer:
    def __init__(self):
        self.model_trainer_config = ModelTrainerConfig()
        logging.info("ModelTrainer initialized for Multi-Output Classification.")

    def initiate_model_trainer(self, target_columns): # Removed train_path, test_path
        try:
            logging.info("Starting model training process for Multi-Output Classification.")
            
            # --- Load preprocessed data from data_transform.py ---
            train_df = pd.read_csv(self.model_trainer_config.train_processed_path)
            test_df = pd.read_csv(self.model_trainer_config.test_processed_path)
            logging.info(f"Loaded preprocessed train_df with shape {train_df.shape} and test_df with shape {test_df.shape}")

            logging.info(f"Columns in train_df AFTER preprocessing: {train_df.columns.tolist()}")
            logging.info(f"Columns in test_df AFTER preprocessing: {test_df.columns.tolist()}")
            
            # --- Load feature columns (generated by data_transform.py) ---
            loaded_feature_columns = load_object(self.model_trainer_config.feature_columns_file_path)
            logging.info(f"Loaded feature columns from {self.model_trainer_config.feature_columns_file_path}: {loaded_feature_columns}")

            # Split features and target - data is already processed
            X_train = train_df[loaded_feature_columns] # Use loaded feature columns
            y_train = train_df[target_columns]

            X_test = test_df[loaded_feature_columns] # Use loaded feature columns
            y_test = test_df[target_columns]

            logging.info(f"Data split. X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")
            logging.info(f"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}")

            # Define models (classifiers)
            models = {
                "RandomForest": RandomForestClassifier(random_state=42),
                "HistGradientBoosting": HistGradientBoostingClassifier(random_state=42),
                "DecisionTree": DecisionTreeClassifier(random_state=42),
                "GradientBoosting": GradientBoostingClassifier(random_state=42),
                "AdaBoost": AdaBoostClassifier(random_state=42),
                "LogisticRegression": LogisticRegression(max_iter=1000, random_state=42, solver='liblinear'),
            }

            # Define hyperparameters with 'estimator__' prefix (for MultiOutputClassifier)
            params = {
                "RandomForest": {
                    "estimator__n_estimators": [50, 100],
                    "estimator__max_depth": [None, 10],
                },
                "HistGradientBoosting": {
                    "estimator__max_iter": [100, 200],
                    "estimator__max_depth": [None, 10],
                },
                "DecisionTree": {
                    "estimator__max_depth": [5, 10],
                    "estimator__min_samples_leaf": [1, 5],
                },
                "GradientBoosting": {
                    "estimator__n_estimators": [50, 100],
                    "estimator__learning_rate": [0.05, 0.1],
                },
                "AdaBoost": {
                    "estimator__n_estimators": [50, 100],
                    "estimator__learning_rate": [0.05, 0.1],
                },
                "LogisticRegression": {},
            }

            logging.info("Evaluating models with GridSearchCV...")
            model_report: dict = evaluate_models(
                X_train=X_train,
                y_train=y_train,
                X_test=X_test,
                y_test=y_test,
                models=models,
                params=params
            )
            logging.info(f"Model evaluation report (F1 Score): {model_report}")

            best_model_score = max(model_report.values())
            best_model_name = [name for name, score in model_report.items() if score == best_model_score][0]
            best_model_base = models[best_model_name]

            if best_model_score < 0.5:
                raise CustomException(f"No best model found with F1-score >= 0.5. Best score: {best_model_score}", sys)
            
            logging.info(f"Best found model: {best_model_name} with F1-score: {best_model_score}")

            final_model = MultiOutputClassifier(best_model_base)
            final_model.fit(X_train, y_train)
            logging.info("Final MultiOutputClassifier trained with the best base model.")

            save_object(
                file_path=self.model_trainer_config.trained_model_file_path,
                obj=final_model
            )
            logging.info(f"Model saved to {self.model_trainer_config.trained_model_file_path}")

            predicted = final_model.predict(X_test)
            f1_macro = f1_score(y_test, predicted, average='macro')
            logging.info(f"Macro F1-score on test set with best model: {f1_macro}")
            
            logging.info("Model training completed successfully for Multi-Output Classification.")
            return f1_macro

        except Exception as e:
            logging.error(f"Error in initiate_model_trainer function: {e}", exc_info=True)
            raise CustomException(e, sys)

if __name__ == "__main__":
    target_columns = ["HeartDisease", "Diabetes", "Hypertension", "Asthma", 
                      "KidneyDisease", "LiverDisease", "Cancer", "Obesity", 
                      "Arthritis", "COPD", "MentalHealthIssue"]
    
    trainer = ModelTrainer()
    # Now calls with target_columns only, as data_transform.py provides processed data paths
    trainer.initiate_model_trainer(
        target_columns=target_columns
    )
